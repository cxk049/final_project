{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载并使用STL-10数据集，用于自监督学习算法SimCLR在ResNet-18上的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 下载并加载STL-10数据集\n",
    "transform = transforms.Compose([  \n",
    "        transforms.RandomResizedCrop(96),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "\n",
    "stl10_train_dataset = datasets.STL10(root='./data', split='unlabeled', download=True, transform=transform)\n",
    "stl10_train_loader = torch.utils.data.DataLoader(stl10_train_dataset, batch_size=256, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确保使用的torch和torchvision的版本对应,以及接下来要使用mps进行调用GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "2.3.1\n",
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义并训练SimCLR模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NT-Xent损失函数定义\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature, device):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def similarity_function(self, x, y):\n",
    "        return torch.mm(x, y.t()) / self.temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        # 获取当前实际批次大小\n",
    "        batch_size = z_i.size(0)\n",
    "        N = 2 * batch_size\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        \n",
    "        sim = self.similarity_function(z, z)\n",
    "        \n",
    "        mask = torch.eye(N, dtype=torch.bool).to(self.device)\n",
    "        sim = sim.masked_fill(mask, -float('inf'))\n",
    "        \n",
    "        pos = torch.cat([torch.diag(sim, batch_size), torch.diag(sim, -batch_size)])\n",
    "        pos = pos.view(N, 1)\n",
    "        \n",
    "        neg = sim.masked_fill(mask, -float('inf')).flatten()\n",
    "        logits = torch.cat((pos, neg.view(N, -1)), dim=1)\n",
    "        \n",
    "        labels = torch.zeros(N, dtype=torch.long).to(self.device)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss\n",
    "\n",
    "\n",
    "# SimCLR 模型定义\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_model, out_dim=256):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = base_model\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return h, z\n",
    "\n",
    "# 自定义数据集类定义\n",
    "class CustomBinaryDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.filenames = data_dict['filenames']\n",
    "        self.images = data_dict['data']\n",
    "        self.labels = data_dict['fine_labels']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 将图像数据从一维数组转换为 32x32x3 的形状\n",
    "        image = image.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 加强的数据增强策略\n",
    "def augment(x):\n",
    "    return x + torch.randn_like(x) * 0.1\n",
    "\n",
    "# 计算准确率函数\n",
    "def calculate_accuracy(z1, z2):\n",
    "    similarity = torch.matmul(z1, z2.T)\n",
    "    preds = similarity.argmax(dim=1)\n",
    "    correct = preds.eq(torch.arange(z1.size(0), device=z1.device)).sum().item()\n",
    "    return correct / z1.size(0)\n",
    "\n",
    "\n",
    "# 训练SimCLR模型的函数\n",
    "def train_simclr(model, loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    num_samples = 0\n",
    "    for i, (x, _) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # 数据增强\n",
    "        x1, x2 = augment(x), augment(x)\n",
    "        \n",
    "        # 获取投影后的特征向量\n",
    "        _, z1 = model(x1)\n",
    "        _, z2 = model(x2)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(z1, z2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += calculate_accuracy(z1, z2) * x.size(0)\n",
    "        num_samples += x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = total_correct / num_samples\n",
    "    print(f'Epoch [{epoch+1}], Loss: {avg_loss:.6f}, Accuracy: {accuracy:.6f}')\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 定义训练函数\n",
    "def train_SimCLR(params, train_loader):\n",
    "    # 设置设备\n",
    "    device = torch.device(params['device'])\n",
    "\n",
    "    # 定义ResNet-18基础模型，并去除分类层\n",
    "    resnet_model = resnet18(weights=params['base_model_weights'])\n",
    "    resnet_model.fc = nn.Identity()\n",
    "\n",
    "    # 初始化SimCLR模型\n",
    "    model = SimCLR(resnet_model, out_dim=params['out_dim']).to(device)\n",
    "\n",
    "    # 定义优化器和损失函数\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=1e-6)  # 加入权重衰减\n",
    "    criterion = NTXentLoss(batch_size=params['batch_size'], temperature=0.5, device=device)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 学习率调度器\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        avg_loss, accuracy = train_simclr(model, train_loader, optimizer, criterion, device, epoch)\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "        scheduler.step()  # 更新学习率\n",
    "\n",
    "    # 保存模型权重\n",
    "    torch.save(model.state_dict(), params['model_save_path'])\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数字典\n",
    "params_stl10 = {\n",
    "    'device': 'mps',  # 计算设备\n",
    "    'base_model_weights': 'DEFAULT',  # 预训练模型的权重，\n",
    "    'out_dim': 256,  # SimCLR 模型的投影输出维度\n",
    "    'learning_rate': 1e-4,  # 学习率\n",
    "    'num_epochs': 15,  # 训练的轮数\n",
    "    'batch_size': 256,  # 批量大小\n",
    "    'model_save_path': 'simclr_stl10.pth',  # 保存训练好的模型权重的路径\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.825628, Accuracy: 0.985410\n",
      "Epoch [2], Loss: 0.695386, Accuracy: 0.999550\n",
      "Epoch [3], Loss: 0.694338, Accuracy: 0.999810\n",
      "Epoch [4], Loss: 0.693898, Accuracy: 0.999870\n",
      "Epoch [5], Loss: 0.693753, Accuracy: 0.999890\n",
      "Epoch [6], Loss: 0.693457, Accuracy: 0.999960\n",
      "Epoch [7], Loss: 0.693385, Accuracy: 0.999930\n",
      "Epoch [8], Loss: 0.693391, Accuracy: 0.999920\n",
      "Epoch [9], Loss: 0.693299, Accuracy: 0.999970\n",
      "Epoch [10], Loss: 0.693268, Accuracy: 0.999980\n",
      "Epoch [11], Loss: 0.693258, Accuracy: 1.000000\n",
      "Epoch [12], Loss: 0.693260, Accuracy: 0.999970\n",
      "Epoch [13], Loss: 0.693238, Accuracy: 0.999980\n",
      "Epoch [14], Loss: 0.693264, Accuracy: 0.999970\n",
      "Epoch [15], Loss: 0.693254, Accuracy: 0.999990\n"
     ]
    }
   ],
   "source": [
    "# 调用训练函数\n",
    "train_SimCLR(params_stl10,stl10_train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载并解析CIFAR数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> <class 'dict'>\n",
      "5 5\n",
      "dict_keys(['filenames', 'batch_label', 'fine_labels', 'coarse_labels', 'data'])\n",
      "dict_keys(['filenames', 'batch_label', 'fine_labels', 'coarse_labels', 'data'])\n"
     ]
    }
   ],
   "source": [
    "# 读取并解析二进制文件\n",
    "train_path = '/Users/fuchenxu/Desktop/computer_vision/final_project/task_1/SIFAR-100/cifar-100-python/train'\n",
    "test_path = '/Users/fuchenxu/Desktop/computer_vision/final_project/task_1/SIFAR-100/cifar-100-python/test'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_data = pickle.load(f, encoding='latin1')\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# 检查 train_data 的内容\n",
    "print(type(train_data),type(test_data))\n",
    "print(len(train_data),len(test_data))\n",
    "print(train_data.keys() if isinstance(train_data, dict) else \"Not a dictionary\")\n",
    "print(test_data.keys() if isinstance(test_data, dict) else \"Not a dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32]) torch.Size([256])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# 自定义数据集类定义\n",
    "class CustomBinaryDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.filenames = data_dict['filenames']\n",
    "        self.images = data_dict['data']\n",
    "        self.labels = data_dict['fine_labels']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 将图像数据从一维数组转换为 32x32x3 的形状\n",
    "        image = image.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 数据增强和标准化\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "train_dataset = CustomBinaryDataset(data_dict=train_data, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "#加载测试集数据\n",
    "test_dataset = CustomBinaryDataset(data_dict=test_data, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# 验证数据加载器是否正常工作\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break\n",
    "for images, labels in test_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义线性分类器并进行训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义线性分类器\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=100):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.encoder = base_model\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            h = self.encoder(x)\n",
    "        x = self.fc1(h)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 训练线性分类器的函数\n",
    "def train_linear_classifier(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == y).sum().item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = total_correct / len(loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 评估线性分类器的函数\n",
    "def evaluate_linear_classifier(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == y).sum().item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = total_correct / len(loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "    \n",
    "# 训练和测试函数\n",
    "def train_and_evaluate_simclr(params, train_loader, test_loader):\n",
    "    # 设置设备\n",
    "    device = torch.device(params['device'])\n",
    "\n",
    "    # 加载预训练的SimCLR模型并选择性的冻结其权重\n",
    "    resnet_model = resnet18(weights=params['base_model_weights'])\n",
    "    resnet_model.fc = nn.Identity()\n",
    "    simclr_model = SimCLR(resnet_model, out_dim=256).to(device)\n",
    "    simclr_model.load_state_dict(torch.load(params['simclr_model_path']))\n",
    "\n",
    "    if params['freeze_pretrained']:\n",
    "        # 冻结预训练模型参数\n",
    "        for param in simclr_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # 创建线性分类器\n",
    "    linear_classifier = LinearClassifier(simclr_model.encoder, num_classes=params['num_classes']).to(device)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(linear_classifier.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # 学习率调度器\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3)\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        train_loss, train_accuracy = train_linear_classifier(linear_classifier, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_accuracy = evaluate_linear_classifier(linear_classifier, test_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch+1}], Train Loss: {train_loss:.6f}, Train Accuracy: {train_accuracy:.6f}')\n",
    "        print(f'Epoch [{epoch+1}], Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')\n",
    "        writer.add_scalars('Loss', {'train': train_loss, 'test': test_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'train': train_accuracy, 'test': test_accuracy}, epoch)\n",
    "        \n",
    "        # 调整学习率\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "    # 保存模型权重\n",
    "    torch.save(linear_classifier.state_dict(), params['model_save_path'])\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数字典\n",
    "params_simclr_frozen = {\n",
    "    'device': 'mps',  # 设备选择\n",
    "    'base_model_weights': 'DEFAULT',\n",
    "    'simclr_model_path': 'simclr_stl10.pth',\n",
    "    'learning_rate': 1e-4,  # 学习率\n",
    "    'batch_size': 256,\n",
    "    'num_epochs': 15,  # 训练的轮数\n",
    "    'model_save_path': 'linear_classifier_frozen.pth',  # 保存模型权重的路径\n",
    "    'num_classes': 100,\n",
    "    'freeze_pretrained': True,  # 是否冻结预训练模型权重\n",
    "}\n",
    "\n",
    "params_simclr_unfrozen = {\n",
    "    'device': 'mps',  # 设备选择\n",
    "    'base_model_weights': 'DEFAULT',\n",
    "    'simclr_model_path': 'simclr_stl10.pth',\n",
    "    'learning_rate': 1e-4,  # 学习率\n",
    "    'batch_size': 256,\n",
    "    'num_epochs': 15,  # 训练的轮数\n",
    "    'model_save_path': 'linear_classifier_unfrozen.pth',  # 保存模型权重的路径\n",
    "    'num_classes': 100,\n",
    "    'freeze_pretrained': False,  # 是否冻结预训练模型权重\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用训练和测试函数\n",
    "train_and_evaluate_simclr(params_simclr_unfrozen, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用在ImageNet数据集上预训练的ResNet-18模型进行线性分类评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和测试函数\n",
    "def train_and_evaluate_imagenet(params, train_loader, test_loader):\n",
    "    # 设置设备\n",
    "    device = torch.device(params['device'])\n",
    "\n",
    "    # 加载ImageNet预训练的ResNet-18模型并冻结其权重\n",
    "    resnet_model = resnet18(weights=params['base_model_weights'])\n",
    "    resnet_model.fc = nn.Identity()\n",
    "\n",
    "    for param in resnet_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 创建线性分类器\n",
    "    linear_classifier = LinearClassifier(resnet_model, num_classes=params['num_classes']).to(device)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(linear_classifier.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        train_loss, train_accuracy = train_linear_classifier(linear_classifier, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_accuracy = evaluate_linear_classifier(linear_classifier, test_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch+1}], Train Loss: {train_loss:.6f}, Train Accuracy: {train_accuracy:.6f}')\n",
    "        print(f'Epoch [{epoch+1}], Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')\n",
    "        writer.add_scalars('Loss', {'train': train_loss, 'test': test_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'train': train_accuracy, 'test': test_accuracy}, epoch)\n",
    "    \n",
    "    # 保存模型权重\n",
    "    torch.save(linear_classifier.state_dict(), params['model_save_path'])\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数字典\n",
    "params_imagenet = {\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'mps',  # 设备选择\n",
    "    'base_model_weights': 'IMAGENET1K_V1',  # 预训练模型的权重\n",
    "    'learning_rate': 1e-4,  # 学习率\n",
    "    'num_epochs': 15,  # 训练的轮数\n",
    "    'model_save_path': 'imagenet_classifier_cifar100.pth',  # 保存模型权重的路径\n",
    "    'num_classes': 100,  # 分类器的类别数量\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss: 4.585081, Train Accuracy: 0.224000\n",
      "Epoch [1], Test Loss: 4.525494, Test Accuracy: 0.380000\n",
      "Epoch [2], Train Loss: 4.474433, Train Accuracy: 0.427200\n",
      "Epoch [2], Test Loss: 4.409912, Test Accuracy: 0.524000\n",
      "Epoch [3], Train Loss: 4.357847, Train Accuracy: 0.576400\n",
      "Epoch [3], Test Loss: 4.304858, Test Accuracy: 0.674000\n",
      "Epoch [4], Train Loss: 4.280235, Train Accuracy: 0.664800\n",
      "Epoch [4], Test Loss: 4.248499, Test Accuracy: 0.708000\n",
      "Epoch [5], Train Loss: 4.237301, Train Accuracy: 0.723600\n",
      "Epoch [5], Test Loss: 4.219965, Test Accuracy: 0.778000\n",
      "Epoch [6], Train Loss: 4.203393, Train Accuracy: 0.763000\n",
      "Epoch [6], Test Loss: 4.184556, Test Accuracy: 0.841000\n",
      "Epoch [7], Train Loss: 4.182959, Train Accuracy: 0.790000\n",
      "Epoch [7], Test Loss: 4.173709, Test Accuracy: 0.827000\n",
      "Epoch [8], Train Loss: 4.163268, Train Accuracy: 0.812400\n",
      "Epoch [8], Test Loss: 4.129063, Test Accuracy: 0.896000\n",
      "Epoch [9], Train Loss: 4.144882, Train Accuracy: 0.852800\n",
      "Epoch [9], Test Loss: 4.126649, Test Accuracy: 0.855000\n",
      "Epoch [10], Train Loss: 4.127467, Train Accuracy: 0.864600\n",
      "Epoch [10], Test Loss: 4.128969, Test Accuracy: 0.882000\n",
      "Epoch [11], Train Loss: 4.117969, Train Accuracy: 0.860400\n",
      "Epoch [11], Test Loss: 4.112004, Test Accuracy: 0.940000\n",
      "Epoch [12], Train Loss: 4.110580, Train Accuracy: 0.882800\n",
      "Epoch [12], Test Loss: 4.095812, Test Accuracy: 0.908000\n",
      "Epoch [13], Train Loss: 4.098245, Train Accuracy: 0.890600\n",
      "Epoch [13], Test Loss: 4.082593, Test Accuracy: 0.919000\n",
      "Epoch [14], Train Loss: 4.092993, Train Accuracy: 0.902600\n",
      "Epoch [14], Test Loss: 4.081005, Test Accuracy: 0.940000\n",
      "Epoch [15], Train Loss: 4.079730, Train Accuracy: 0.921200\n",
      "Epoch [15], Test Loss: 4.069187, Test Accuracy: 0.970000\n"
     ]
    }
   ],
   "source": [
    "# 调用训练和测试函数\n",
    "train_and_evaluate_imagenet(params_imagenet, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在CIFAR-100数据集上从零开始训练ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和测试函数\n",
    "def train_and_evaluate_cifar_resnet(params, train_loader, test_loader):\n",
    "    # 设置设备\n",
    "    device = torch.device(params['device'])\n",
    "\n",
    "    # 定义ResNet-18模型\n",
    "    cifar_resnet_model = resnet18(weights=None)\n",
    "    cifar_resnet_model.fc = nn.Linear(512, 100)  # 适配CIFAR-100\n",
    "    cifar_resnet_model = cifar_resnet_model.to(device)  # 将模型加载到设备上\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cifar_resnet_model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        train_loss, train_accuracy = train_linear_classifier(cifar_resnet_model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_accuracy = evaluate_linear_classifier(cifar_resnet_model, test_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch+1}], Train Loss: {train_loss:.6f}, Train Accuracy: {train_accuracy:.6f}')\n",
    "        print(f'Epoch [{epoch+1}], Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')\n",
    "        writer.add_scalars('Loss', {'train': train_loss, 'test': test_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'train': train_accuracy, 'test': test_accuracy}, epoch)\n",
    "    \n",
    "    # 保存模型权重\n",
    "    torch.save(cifar_resnet_model.state_dict(), params['model_save_path'])\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数字典\n",
    "params_cifar = {\n",
    "    'device': 'mps',  # 设备选择\n",
    "    'learning_rate': 1e-4,  # 学习率\n",
    "    'num_epochs': 15,  # 训练的轮数\n",
    "    'model_save_path': 'cifar_resnet_cifar100.pth',  # 保存模型权重的路径\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss: 4.575025, Train Accuracy: 0.078960\n",
      "Epoch [1], Test Loss: 4.448085, Test Accuracy: 0.117000\n",
      "Epoch [2], Train Loss: 4.374245, Train Accuracy: 0.131580\n",
      "Epoch [2], Test Loss: 4.319279, Test Accuracy: 0.159300\n",
      "Epoch [3], Train Loss: 4.271965, Train Accuracy: 0.166800\n",
      "Epoch [3], Test Loss: 4.236952, Test Accuracy: 0.189000\n",
      "Epoch [4], Train Loss: 4.194817, Train Accuracy: 0.200940\n",
      "Epoch [4], Test Loss: 4.161407, Test Accuracy: 0.229800\n",
      "Epoch [5], Train Loss: 4.127726, Train Accuracy: 0.229680\n",
      "Epoch [5], Test Loss: 4.128075, Test Accuracy: 0.242700\n",
      "Epoch [6], Train Loss: 4.082789, Train Accuracy: 0.250560\n",
      "Epoch [6], Test Loss: 4.083178, Test Accuracy: 0.262500\n",
      "Epoch [7], Train Loss: 4.035984, Train Accuracy: 0.269760\n",
      "Epoch [7], Test Loss: 4.031852, Test Accuracy: 0.278400\n",
      "Epoch [8], Train Loss: 3.993523, Train Accuracy: 0.295380\n",
      "Epoch [8], Test Loss: 4.024248, Test Accuracy: 0.284400\n",
      "Epoch [9], Train Loss: 3.953982, Train Accuracy: 0.305940\n",
      "Epoch [9], Test Loss: 3.966776, Test Accuracy: 0.306900\n",
      "Epoch [10], Train Loss: 3.922087, Train Accuracy: 0.324660\n",
      "Epoch [10], Test Loss: 3.942696, Test Accuracy: 0.324900\n",
      "Epoch [11], Train Loss: 3.892085, Train Accuracy: 0.345660\n",
      "Epoch [11], Test Loss: 3.955053, Test Accuracy: 0.331500\n",
      "Epoch [12], Train Loss: 3.856894, Train Accuracy: 0.361620\n",
      "Epoch [12], Test Loss: 3.888311, Test Accuracy: 0.337800\n",
      "Epoch [13], Train Loss: 3.822343, Train Accuracy: 0.371160\n",
      "Epoch [13], Test Loss: 3.843184, Test Accuracy: 0.376800\n",
      "Epoch [14], Train Loss: 3.801844, Train Accuracy: 0.386040\n",
      "Epoch [14], Test Loss: 3.817108, Test Accuracy: 0.387900\n",
      "Epoch [15], Train Loss: 3.771347, Train Accuracy: 0.391620\n",
      "Epoch [15], Test Loss: 3.807431, Test Accuracy: 0.395400\n"
     ]
    }
   ],
   "source": [
    "# 调用训练和测试函数\n",
    "train_and_evaluate_cifar_resnet(params_cifar, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用Tensorboard可视化的训练过程中的loss曲线变化以及Linear classification过程中accuracy的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "E0615 12:11:55.861474 6230732800 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 363, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 324, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 122, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "E0615 12:11:55.892637 6180253696 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 363, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 324, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 122, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "E0615 12:12:25.861338 6197080064 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 363, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 324, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 122, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "E0615 12:12:55.877560 6213906432 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 363, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/serving.py\", line 324, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/opt/anaconda3/envs/final/lib/python3.8/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 122, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"/Users/fuchenxu/Desktop/computer_vision/final_project/task_1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
